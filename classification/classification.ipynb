{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLpaiWp2PqGoxpeDDHuPyf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrispoole70/langchain-tutorials/blob/main/classification/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Classify Text into Labels](https://python.langchain.com/docs/tutorials/classification/)"
      ],
      "metadata": {
        "id": "vyqwwK31Q0uE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU6kq7hKQMxs"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU \"langchain[openai]\""
      ],
      "metadata": {
        "id": "JWH5K1SDRR2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "0kDCCrptSM0A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "WghgSOHdTQ8K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the chat model"
      ],
      "metadata": {
        "id": "pMPN2fLOWQdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
      ],
      "metadata": {
        "id": "0NwxrF8pTUXT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(llm).__name__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZKfzdH1gXDNP",
        "outputId": "2b90cd14-7260-45d8-f1a7-92640853200c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ChatOpenAI'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an input message for the chat model"
      ],
      "metadata": {
        "id": "8veTiyGuWZlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagging_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Extract the desired information from the following passage.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Passage:\n",
        "{input}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "Qn4b3fdzTkLA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the schema of the output message the chat model should return"
      ],
      "metadata": {
        "id": "bqwCN8WpWlPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classification(BaseModel):\n",
        "  sentiment: str = Field(description='The sentiment of the text')\n",
        "  aggressiveness: int = Field(description='How aggressive the text is on a scale from 1 to 10')\n",
        "  language: str = Field(description='The language the text is written in')"
      ],
      "metadata": {
        "id": "qB9AUDg5Up6I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After defining the output message schema, the chat model has two steps:\n",
        "1. Send the input message to the LLM\n",
        "2. A function will be called behind the scenes to format the output message as a `Classification` object"
      ],
      "metadata": {
        "id": "pS5hy7q9Yt36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm = llm.with_structured_output(Classification)"
      ],
      "metadata": {
        "id": "7vzAaDz5VJ_K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(structured_llm).__name__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q6dtXprxW7UX",
        "outputId": "0f565cc3-67e6-4793-878c-3c2ce93db649"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RunnableSequence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(structured_llm.steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vkQcOqwXNom",
        "outputId": "f9459b3a-d0d0-49b3-ca2c-56c942fd071c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm.steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT-QPk8fXUTf",
        "outputId": "ad38a516-69f4-4292-80cc-c86320ab3106"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d54f1711bd0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7d54f16cdbd0>, root_client=<openai.OpenAI object at 0x7d54f1ed4150>, root_async_client=<openai.AsyncOpenAI object at 0x7d54f1711e10>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'response_format': <class '__main__.Classification'>, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema', 'strict': None}, 'schema': {'type': 'function', 'function': {'name': 'Classification', 'description': '', 'parameters': {'properties': {'sentiment': {'description': 'The sentiment of the text', 'type': 'string'}, 'aggressiveness': {'description': 'How aggressive the text is on a scale from 1 to 10', 'type': 'integer'}, 'language': {'description': 'The language the text is written in', 'type': 'string'}}, 'required': ['sentiment', 'aggressiveness', 'language'], 'type': 'object'}}}}}, config={}, config_factories=[]),\n",
              " RunnableBinding(bound=RunnableLambda(...), kwargs={}, config={}, config_factories=[], custom_output_type=<class '__main__.Classification'>)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though `Classification` is a class, the LLM interacts with it as a function. The properties `sentiment`, `aggressiveness`, and `language` are treated as arguments to the function."
      ],
      "metadata": {
        "id": "llqgvdybZ5EM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Classification.model_json_schema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKfRGVowX4dW",
        "outputId": "9ba3e487-17db-4ea1-9bcd-3fea235fab97"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'properties': {'sentiment': {'description': 'The sentiment of the text',\n",
              "   'title': 'Sentiment',\n",
              "   'type': 'string'},\n",
              "  'aggressiveness': {'description': 'How aggressive the text is on a scale from 1 to 10',\n",
              "   'title': 'Aggressiveness',\n",
              "   'type': 'integer'},\n",
              "  'language': {'description': 'The language the text is written in',\n",
              "   'title': 'Language',\n",
              "   'type': 'string'}},\n",
              " 'required': ['sentiment', 'aggressiveness', 'language'],\n",
              " 'title': 'Classification',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format the input message with a passage in Spanish"
      ],
      "metadata": {
        "id": "bedf05mxW10M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
        "prompt = tagging_prompt.invoke({'input': inp})"
      ],
      "metadata": {
        "id": "e0vAs-_ZVhGd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNFUmggVWFeG",
        "outputId": "7404e7f5-ed63-41c0-a15e-ea296281836e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"\\nExtract the desired information from the following passage.\\n\\nOnly extract the properties mentioned in the 'Classification' function.\\n\\nPassage:\\nEstoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\\n\", additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Send the input message to the LLM"
      ],
      "metadata": {
        "id": "4-z2Fdsja_zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = structured_llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "2MOIB3HcWGz3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output message is a `Classification` object"
      ],
      "metadata": {
        "id": "QVYYyAIhbM0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtuWQyLUa9NC",
        "outputId": "6d252425-dded-4fd6-f8f4-103ec6706dd0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The response can also be turned into a dictionary"
      ],
      "metadata": {
        "id": "-nB-s8MfbZ68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AVaw_k4a-Ly",
        "outputId": "258fea50-68c8-4e68-f37e-18c578e20639"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'positive', 'aggressiveness': 1, 'language': 'Spanish'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finer Control"
      ],
      "metadata": {
        "id": "5P9Phpvmgn8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to defining each property in the output schema, we can declare which properties are required and what possible values each can have"
      ],
      "metadata": {
        "id": "RDVQllLOg6fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = []\n",
        "\n",
        "[my_list.append(i) for i in range(1, 11)]\n",
        "\n",
        "my_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD2r11wMi5G4",
        "outputId": "dcd00ca3-b48c-4be1-d889-9591537ee82f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Classification(BaseModel):\n",
        "  sentiment: str = Field(description='The sentiment of the text', enum=['happy', 'neutral', 'sad'])\n",
        "  aggressiveness: int = Field(description='How aggressive the text is on a scale from 1 to 10', enum=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "  language: str = Field(description='The language the text is written in', enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"])"
      ],
      "metadata": {
        "id": "Hn72ZlhCbYVC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm = llm.with_structured_output(Classification)"
      ],
      "metadata": {
        "id": "XG1gf7JXjJ3W"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = structured_llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "9BctiwqrjpOR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR2Np_Wljzia",
        "outputId": "a4b3eb70-1cc0-49ec-b719-c13f80d96e4f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification(sentiment='happy', aggressiveness=1, language='spanish')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUb1YFpBj0yz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}